{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40996eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import importlib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve,auc,roc_auc_score\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ee6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7731f0",
   "metadata": {},
   "source": [
    "## This code is used for extraction feature matrix from DTI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00bccdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def get_D_T_in_DTI(G):\n",
    "    '''\n",
    "    Return Drugs and targets with interactions in G\n",
    "    '''\n",
    "    D,T = G.nonzero()\n",
    "    D = set(D)\n",
    "    T = set(T)\n",
    "    return D,T\n",
    "\n",
    "def calculate_score(d,t,D_interact,T_interact,aD_sim,aT_sim,r=0.6):\n",
    "    #loop over all pairs of similarities\n",
    "    scores = []\n",
    "    for D_sim in aD_sim:\n",
    "        for T_sim in aT_sim:\n",
    "            f_score = 0\n",
    "            for i in D_interact:\n",
    "                for j in T_interact:\n",
    "                    if i!=d and j!=t:\n",
    "                        score = D_sim[i,d]**r * T_sim[j,t]**(1-r)\n",
    "                        #keep the max score\n",
    "                        f_score = max(f_score,score)\n",
    "            scores.append(f_score)\n",
    "    #print(scores)\n",
    "    return scores\n",
    "def get_features(G,aD_sim,aT_sim):\n",
    "    '''\n",
    "    DTI matrix\n",
    "    '''\n",
    "    # get the D and Ts in interaction\n",
    "    features = []\n",
    "    D,T = get_D_T_in_DTI(G)\n",
    "    \n",
    "    for i in range(G.shape[0]):\n",
    "        for j in range(G.shape[1]):\n",
    "            features.append(calculate_score(i,j,D,T,aD_sim,aT_sim))\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247ac40c",
   "metadata": {},
   "source": [
    "## Function in the following block will drive the classification process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c0161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classification(data,labels,test_idx):\n",
    "    All_scores = []\n",
    "    length = len(data)\n",
    "    train_idx = []\n",
    "    for idx in range(length):\n",
    "        if idx not in test_idx:\n",
    "            train_idx.append(idx)\n",
    "    data = np.array(data)\n",
    "    test_idx = np.array(test_idx)\n",
    "    train_idx = np.array(train_idx)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    X_train, X_test = data[train_idx,], data[test_idx,]\n",
    "    y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "\n",
    "    print(X_train.shape)\n",
    "    # scale the data\n",
    "    max_abs_scaler = MaxAbsScaler()\n",
    "    X_train_maxabs_fit = max_abs_scaler.fit(X_train) \n",
    "\n",
    "    X_train_maxabs_transform = max_abs_scaler.transform(X_train)\n",
    "\n",
    "    X_test_maxabs_transform = max_abs_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    clf = LogisticRegression(class_weight='balanced')\n",
    "    print (X_train_maxabs_transform.shape,y_train.shape)\n",
    "    clf.fit(X_train_maxabs_transform, y_train)\n",
    "    \n",
    "    \n",
    "\n",
    "    scores_testing =  clf.predict_proba(X_test_maxabs_transform)[:, 1]\n",
    "\n",
    "\n",
    "    y_pred = clf.predict(X_test_maxabs_transform)\n",
    "\n",
    "\n",
    "    precision_testing, recall_testing, _ =   precision_recall_curve(y_test, scores_testing, pos_label=1)\n",
    "\n",
    "    AUPR = auc(recall_testing, precision_testing)\n",
    "    AUROC = roc_auc_score(y_test,scores_testing)\n",
    "\n",
    "    print(\"AUPR is: {}\".format(AUPR))\n",
    "    print(\"AUROC is: {}\".format(AUROC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84c10a",
   "metadata": {},
   "source": [
    "## Loading DTI matrix and similarity matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64dd4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTI_file = 'data/nr_admat_dgc_mat_2_line.txt'\n",
    "DD_similarities = 'data/nr_D_similarities.txt'\n",
    "TT_similarities = 'data/nr_T_similarities.txt'\n",
    "\n",
    "#Loading D and T metadata\n",
    "D,T,dDs,dTs,diDs,diTs = utils.get_D_T_info(DTI_file)\n",
    "\n",
    "#get DTIs\n",
    "DTI = utils.get_edge_list(DTI_file) #this returns a list of interactions\n",
    "\n",
    "#create an adj matrix \n",
    "DTI_adj = utils.get_adj_matrix_from_relation(DTI,dDs,dTs)\n",
    "row,col = DTI_adj.shape\n",
    "labels = utils.mat2vec(DTI_adj)\n",
    "\n",
    "# Load Drug similarity matrix\n",
    "aDSim = utils.get_similarities(DD_similarities,dDs)\n",
    "\n",
    "# Load Target similarity matrix\n",
    "aTSim = utils.get_similarities(TT_similarities,dTs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f8c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate cross validation data for pair mode\n",
    "cv_data = utils.cross_validation(DTI_adj,seeds=[2], cv=1, num=10)\n",
    "for fold in cv_data[2]:\n",
    "    W = fold[0] # get the masking matrix for DTI\n",
    "    DTI_train = DTI_adj*W #mask test pairs from DTI\n",
    "    \n",
    "    # Adding similarity based on network\n",
    "    DT_impute_D = utils.impute_zeros(DTI_train,aDSim[0])\n",
    "    DT_impute_T = utils.impute_zeros(np.transpose(DTI_train),aTSim[0])\n",
    "\n",
    "    GIP_D = utils.Get_GIP_profile(np.transpose(DT_impute_D),\"d\")\n",
    "    GIP_T = utils.Get_GIP_profile(DT_impute_T,\"t\")\n",
    "    \n",
    "    Final_sim_D = aDSim + [GIP_D]\n",
    "    Final_sim_T = aTSim + [GIP_T]\n",
    "    features = get_features(DTI_train,Final_sim_D,Final_sim_T)\n",
    "    test_idx = [i*col+j for (i,j) in fold[1]]\n",
    "    run_classification(features,labels,test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea809512",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "- How can we imporive the accuracy more?\n",
    "- Can we look into other data sets? Try look into: https://www.cin.ufpe.br/~acan/kronrlsmkl/data.zip \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6043393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
